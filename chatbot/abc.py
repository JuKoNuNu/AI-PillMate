#pip install streamlit pandas pillow pytesseract requests
# ì‹¤í–‰ : streamlit run app.py


import os
import re
import requests
import difflib
import numpy as np
import pandas as pd
from PIL import Image
import cv2
import easyocr
import streamlit as st
from dotenv import load_dotenv
import openai
from openai import OpenAI
from llama_index.core import (
    VectorStoreIndex,
    Document,
    StorageContext,
    load_index_from_storage,
    Settings
)
from llama_index.llms.openai import OpenAI as LlamaOpenAI
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core.response_synthesizers import get_response_synthesizer
from llama_index.core.retrievers import VectorIndexRetriever


load_dotenv()
# print(os.environ['OPENAI_API_KEY'])
OPENAI_API_KEY = os.environ['OPENAI_API_KEY']
client = openai.OpenAI(api_key=OPENAI_API_KEY)  # ìˆ˜ì • ì˜ˆì •
openai_key = os.getenv("OPENAI_API_KEY") # ìˆ˜ì • ì˜ˆì •
google_key = os.getenv("GOOGLE_API_KEY")
google_cse = os.getenv("GOOGLE_CSE_ID")


st.set_page_config(page_title="AI ê¸°ë°˜ ì•½ ì¸ì‹ ì‹œìŠ¤í…œ", layout="wide")
reader = easyocr.Reader(['en', 'ko'])

def easyocr_extract_text(image: Image.Image):
    img_array = np.array(image)
    result = reader.readtext(img_array, detail=0)
    return " ".join(result)

def crop_pill_area(image):
    img_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
    gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (7, 7), 0)
    _, thresh = cv2.threshold(blur, 180, 255, cv2.THRESH_BINARY_INV)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not contours:
        return image
    for cnt in sorted(contours, key=cv2.contourArea, reverse=True):
        x, y, w, h = cv2.boundingRect(cnt)
        roi = gray[y:y + h, x:x + w]
        text = reader.readtext(roi, detail=0)
        if any(text):
            cropped = img_cv[y:y + h, x:x + w]
            return Image.fromarray(cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB))
    return image

def clean_str(s):
    return ''.join(filter(str.isalnum, str(s))).upper() if isinstance(s, str) else ''

def extract_ingredients(text):
    return re.findall(r'([ê°€-í£A-Za-z]+)\s*([\d\.]+)\s*(mg|g|ã|ë°€ë¦¬ê·¸ë¨)', text)

# ì§ˆì˜ 
def chat_with_pill_info(pill_info, question):
    question = question.lower()
    other_drugs = ["íƒ€ì´ë ˆë†€", "ì´ë¶€í”„ë¡œíœ", "ë¶€ë£¨íœ", "ì•„ìŠ¤í”¼ë¦°"]
    if any(keyword in question for keyword in ["íš¨ëŠ¥", "ê¸°ëŠ¥", "ì–´ë–¤ ì§ˆë³‘", "ë¬´ìŠ¨ ë³‘"]):
        return pill_info.get("íš¨ëŠ¥íš¨ê³¼", "ì •ë³´ ì—†ìŒ")
    elif any(keyword in question for keyword in ["ë³µìš©", "ì–¸ì œ", "ì–¼ë§ˆë‚˜", "ìš©ë²•", "ìš©ëŸ‰", "ëª‡ ë²ˆ"]):
        return pill_info.get("ìš©ë²•ìš©ëŸ‰", "ì •ë³´ ì—†ìŒ")
    elif any(keyword in question for keyword in ["ì£¼ì˜", "ì£¼ì˜ì‚¬í•­", "ì¡°ì‹¬", "ê¸ˆê¸°", "ê²½ê³ ", "ì§€ì¼œì•¼"]):
        atpn = str(pill_info.get("ì‚¬ìš©ìƒ ì£¼ì˜ì‚¬í•­", "") or "")
        caution = str(pill_info.get("ì‚¬ìš©ì‹œì£¼ì˜ì‚¬í•­", "") or "")
        return atpn + "\n\n" + caution if atpn.strip() or caution.strip() else "ì •ë³´ ì—†ìŒ"
    elif any(keyword in question for keyword in ["ì„±ë¶„", "ë¬´ì—‡ì´", "ë“¤ì–´ìˆ"]):
        return pill_info.get("ì„±ë¶„ì •ë³´", "ì •ë³´ ì—†ìŒ")
    elif any(keyword in question for keyword in ["ë³´ê´€", "ì €ì¥"]):
        return pill_info.get("ì €ì¥ë°©ë²•", "ì •ë³´ ì—†ìŒ")
    elif any(keyword in question for keyword in ["ì‚¬ìš©ê¸°í•œ", "ì–¸ì œê¹Œì§€", "ìœ í†µê¸°í•œ", "ê¸°í•œ"]):
        return pill_info.get("ì‚¬ìš©ê¸°ê°„", "ì •ë³´ ì—†ìŒ")
    elif any(keyword in question for keyword in ["ì„±ì¸", "ì–´ë¥¸", "ì„±ì¸ì´ ë¨¹ì–´ë„", "ì„±ì¸ì´ ë³µìš©"]):
        caution = str(pill_info.get("ì‚¬ìš©ìƒ ì£¼ì˜ì‚¬í•­", "") or "") + " " + str(pill_info.get("ì‚¬ìš©ì‹œì£¼ì˜ì‚¬í•­", "") or "")
        if "ì†Œì•„" in caution or "ì–´ë¦°ì´" in caution:
            return "ì„±ì¸ ë³µìš© ê´€ë ¨ ì£¼ì˜ì‚¬í•­:\n" + caution
        return "ì„±ì¸ ë³µìš©ì— íŠ¹ë³„í•œ ì œí•œì‚¬í•­ì€ ì–¸ê¸‰ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
    elif any(name in question for name in other_drugs) and any(keyword in question for keyword in ["ê°™ì´", "ë³‘ìš©", "ë™ì‹œì—", "í•¨ê»˜", "ë³µìš©"]):
        inter = str(pill_info.get("ìƒí˜¸ì‘ìš©", "") or "") + " " + str(pill_info.get("ì‚¬ìš©ìƒ ì£¼ì˜ì‚¬í•­", "") or "")
        if inter.strip():
            return f"ë³‘ìš© ê´€ë ¨ ì£¼ì˜ì‚¬í•­:\n" + inter
        return f"ë³‘ìš© ë³µìš©ì— ëŒ€í•œ ì •ë³´ëŠ” ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    elif any(keyword in question for keyword in ["ì„ì‹ ", "ì„ì‚°ë¶€","ì„ë¶€"]):
        atpn = str(pill_info.get("ì‚¬ìš©ìƒ ì£¼ì˜ì‚¬í•­", "") or "")
        if "ì„ë¶€" in atpn or "ì„ì‹ " in atpn:
            return "ì„ì‹  ì¤‘ ë³µìš© ì£¼ì˜ì‚¬í•­:\n" + atpn
        return "ì„ì‹  ì¤‘ ë³µìš©ì— ëŒ€í•œ íŠ¹ë³„í•œ ì£¼ì˜ì‚¬í•­ì€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    elif any(keyword in question for keyword in ["ì§ˆë³‘", "ê°„", "ì‹ ì¥", "ê³ í˜ˆì••", "ë‹¹ë‡¨"]):
        caution = str(pill_info.get("ì‚¬ìš©ìƒ ì£¼ì˜ì‚¬í•­", "") or "")
        return "ê¸°ì € ì§ˆí™˜ ê´€ë ¨ ì£¼ì˜ì‚¬í•­:\n" + (caution if caution.strip() else "ì •ë³´ ì—†ìŒ")
    else:
        return "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì€ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

def check_drug_interaction_summary(pill_list):
    warnings = []
    safe_pairs = []

    for i in range(len(pill_list)):
        for j in range(i + 1, len(pill_list)):
            p1 = pill_list[i]
            p2 = pill_list[j]
            p1_name = p1.get("ì œí’ˆëª…", f"ì•½{i+1}")
            p2_name = p2.get("ì œí’ˆëª…", f"ì•½{j+1}")
            inter1 = str(p1.get("ìƒí˜¸ì‘ìš©", "") or "") + " " + str(p1.get("ì‚¬ìš©ìƒ ì£¼ì˜ì‚¬í•­", "") or "")
            inter2 = str(p2.get("ìƒí˜¸ì‘ìš©", "") or "") + " " + str(p2.get("ì‚¬ìš©ìƒ ì£¼ì˜ì‚¬í•­", "") or "")
            combined = inter1.lower() + " " + inter2.lower()
            if p1_name.lower() in combined or p2_name.lower() in combined or any(
                keyword in combined for keyword in ["ë³‘ìš©", "ê°™ì´", "ë™ì‹œ", "ë³µí•©", "í•¨ê»˜"]
            ):
                warnings.append(f"- **{p1_name} â†” {p2_name}**: ë³‘ìš© ì‹œ ì£¼ì˜ì‚¬í•­ì´ ìˆìŠµë‹ˆë‹¤.")
            else:
                safe_pairs.append(f"{p1_name}, {p2_name}")

    result = "### â–¶ ì„ íƒí•œ ì•½ë“¤ ê°„ì˜ ë³‘ìš© ì—¬ë¶€ ë¶„ì„\n\n"
    if warnings:
        result += "#### ! ì£¼ì˜ê°€ í•„ìš”í•œ ì¡°í•©:\n" + "\n".join(warnings) + "\n\n"
    if safe_pairs:
        result += "#### ! ë³‘ìš©ì— íŠ¹ë³„í•œ ì£¼ì˜ì‚¬í•­ì´ ì—†ëŠ” ì¡°í•©:\n" + ", ".join(safe_pairs) + "\n"

    return result

def check_ingredient_overlap_and_dosage(pill_list, quantities):
    ingredient_total = {}
    warnings = []

    for pill, qty in zip(pill_list, quantities):
        raw = pill.get("ì„±ë¶„ì •ë³´", "")
        extracted = extract_ingredients(raw)
        for name, amount, unit in extracted:
            try:
                mg = float(amount)
                if unit in ["g"]:
                    mg *= 1000
                total_mg = mg * qty
                ingredient_total[name] = ingredient_total.get(name, 0) + total_mg
            except:
                continue

    # í•˜ë£¨ ê¶Œì¥ëŸ‰ ì„ì˜ ê¸°ì¤€ ì˜ˆì‹œ 
    recommended_limits = {
        "ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ": 4000,
        "ì´ë¶€í”„ë¡œíœ": 2400,
    }

    for name, total in ingredient_total.items():
        if name in recommended_limits and total > recommended_limits[name]:
            warnings.append(f"- ! **{name}**: ì´ {total}mg ë³µìš©ì€ 1ì¼ ê¶Œì¥ëŸ‰ {recommended_limits[name]}mg ì´ˆê³¼ì…ë‹ˆë‹¤.")

    duplicates = [name for name, count in pd.Series([n for (n, _, _) in sum([extract_ingredients(p.get("ì„±ë¶„ì •ë³´", "")) for p in pill_list], [])]).value_counts().items() if count > 1]
    if duplicates:
        warnings.append("- ! **ì¤‘ë³µ ì„±ë¶„**: " + ", ".join(duplicates) + " ë³µìš© ì£¼ì˜ í•„ìš”")

    if not warnings:
        return "ì„±ë¶„ ì¤‘ë³µ ë° ê¶Œì¥ëŸ‰ ì´ˆê³¼ ì—†ì´ ë³µìš© ê°€ëŠ¥í•©ë‹ˆë‹¤."
    return "### ! ì„±ë¶„ ë° ìš©ëŸ‰ ì£¼ì˜ì‚¬í•­\n" + "\n".join(warnings)

def is_combination_question(question: str) -> bool:
    comb_keywords = ["ë³‘ìš©", "í•¨ê»˜", "ê°™ì´", "ë™ì‹œ", "ë³µìš©", "ë³‘ìš©ê¸ˆê¸°", "ë³‘ìš©ì£¼ì˜", "ë³‘ìš©íˆ¬ì—¬", "ë³µí•©"]
    q = question.lower()
    return any(k in q for k in comb_keywords)

# ì—‘ì…€ ë°ì´í„° ë¡œë”©
@st.cache_data
def load_excel_data():
    return pd.read_excel("txta.xlsx")

# ë¬¸ì„œ ë¡œë”© (RAGìš©)
def load_docs_from_excel(filepath):
    df_local = pd.read_excel(filepath)
    documents = []
    for _, row in df_local.iterrows():
        content = f"""
        ì œí’ˆëª…: {row.get('ì œí’ˆëª…')}
        íš¨ëŠ¥íš¨ê³¼: {row.get('íš¨ëŠ¥íš¨ê³¼')}
        êµ¬ë¶„: {row.get('êµ¬ë¶„')}
        ì‚¬ìš©ì‹œì£¼ì˜ì‚¬í•­: {row.get('ì‚¬ìš©ì‹œì£¼ì˜ì‚¬í•­', '')}
        ì €ì¥_ì´ë¯¸ì§€_íŒŒì¼ëª…: {row.get('ì €ì¥_ì´ë¯¸ì§€_íŒŒì¼ëª…', '')}
        """
        documents.append(Document(text=content.strip()))
    return documents

# LlamaIndex ì¿¼ë¦¬ ì—”ì§„ ì„¤ì •

@st.cache_resource(show_spinner=True)
def get_query_engine():
    persist_dir = "./index_store"
    
    if not os.path.exists(persist_dir):
        docs = load_docs_from_excel("txta.xlsx")
        index = VectorStoreIndex.from_documents(docs)
        index.storage_context.persist(persist_dir=persist_dir)

    storage_context = StorageContext.from_defaults(persist_dir=persist_dir)
    index = load_index_from_storage(storage_context)

    # LLM ì„¤ì •
    llm = LlamaOpenAI(
        model="gpt-4o-mini",
        temperature=0.3,
        system_prompt=(
            "ë‹¹ì‹ ì€ í•œêµ­ì–´ë¡œë§Œ ëŒ€ë‹µí•´ì•¼í•©ë‹ˆë‹¤.\n"
            "ë‹¹ì‹ ì€ ì•½ì‚¬ë¡œì„œ ì•½ì— ëŒ€í•œ ì •ë³´ë¥¼ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë§ê²Œ ì¹œì ˆí•˜ê³  ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤."
            "ì˜ˆì‹œ"
            "ê°ê¸°ì— ê±¸ë¦°ê±° ê°™ì•„ -> ë‹¹ì‹ ì€ ê°ê¸°ì— ê±¸ë ¸ìŠµë‹ˆë‹¤. ê°ê¸°ì˜ ì¦ìƒì€ ì—´, ê¸°ì¹¨, ì½§ë¬¼ ë“±ì´ ìˆìœ¼ë©° ì´ ì•½ 'ì œí’ˆëª…'ì€ ì´ëŸ¬í•œ ì¦ìƒì— íš¨ê³¼ì ì…ë‹ˆë‹¤. ì‚¬ìš©ë°©ë²•ì€ XXX, ë¶€ì‘ìš©ì´ë‚˜ ì£¼ì˜ì‚¬í•­ì€ XXXì…ë‹ˆë‹¤."
            "ì§„ì§œ ì•½ì‚¬ê°€ ì„¤ëª…í•˜ë“¯ì´ ì„¤ëª…í•´ì•¼í•˜ë©° ìµœì†Œ 2ì¤„ì€ ë„˜ì–´ì•¼ í•©ë‹ˆë‹¤."
            "ì œí’ˆëª… : XXX\n"
            "êµ¬ë¶„ : XXX\n"
            "íš¨ëŠ¥íš¨ê³¼ : XXX\n\n"
            "ê·¸ ë‹¤ìŒ ì¤„ì— ë‹¤ìŒ ì§€ì¹¨ì„ ë”°ë¦…ë‹ˆë‹¤:\n"
            "\n"

        )
    )
    Settings.llm = llm

    # êµ¬ì„±
    retriever = VectorIndexRetriever(index=index, similarity_top_k=2)
    response_synthesizer = get_response_synthesizer(response_mode="tree_summarize")

    query_engine = RetrieverQueryEngine(
        retriever=retriever,
        response_synthesizer=response_synthesizer
    )

    return query_engine

#ê¸°ë³¸ì ì¸ ëŒ€í™”
def is_small_talk(text):
    small_talk_keywords = ["ì•ˆë…•", "ê³ ë§ˆì›Œ", "ì˜ì", "ë­í•´", "í•˜ì´", "ë°˜ê°€ì›Œ", "ì¢‹ì€ í•˜ë£¨", "ã…ã…‡", "hello", "hi","ê³ ë§™ìŠµë‹ˆë‹¤","ë°˜ê°€ì›Œ","êº¼ì ¸","ìŒ"]
    return any(keyword in text.lower() for keyword in small_talk_keywords)

# êµ¬ê¸€ ì´ë¯¸ì§€ ê²€ìƒ‰ (ì´ë¯¸ì§€ URL ë¦¬ìŠ¤íŠ¸ ë°˜í™˜)
def google_image_search(api_key, cse_id, query, num=1):
    url = "https://www.googleapis.com/customsearch/v1"
    params = {
        "key": api_key,
        "cx": cse_id,
        "q": query,
        "searchType": "image",
        "num": num,
    }
    response = requests.get(url, params=params)
    results = response.json()
    return [item["link"] for item in results.get("items", [])]

# Streamlitì— ì´ë¯¸ì§€ í‘œì‹œ í•¨ìˆ˜
def show_images(image_urls):
    for url in image_urls:
        st.image(url, width=300)

# GPTë¡œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
def extract_keyword(question):
    messages = [
            {"role": "system", "content": (
            "ë‹¹ì‹ ì€ í•œêµ­ì–´ ì§ˆë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì •í™•íˆ í•œ ë‹¨ì–´ë¡œ ì¶”ì¶œí•˜ëŠ” AI ì•½ì‚¬ì…ë‹ˆë‹¤. "
            "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ì¦ìƒ ë˜ëŠ” ì•½ê³¼ ê´€ë ¨ëœ ë‹¨ì–´ë§Œ ë½‘ì•„ì•¼ í•©ë‹ˆë‹¤. "
            "ì˜ˆì‹œ:\n"
            "'ê°ê¸° ê±¸ë¦° ê²ƒ ê°™ì•„' â†’ 'ê°ê¸°'\n"
            "'ë‘í†µì´ ì‹¬í•´ìš”' â†’ 'ë‘í†µ'\n"
            "'ì–´ì§€ëŸ½ê³  ê¸°ìš´ì´ ì—†ì–´ìš”' â†’ 'ì–´ì§€ëŸ¼ì¦'\n"
            "'ëª©ì´ ë”°ë”ê±°ë¦¬ê³  ì—´ì´ ë‚˜ìš”' â†’ 'ëª©ê°ê¸°'\n"
            "ì •í™•íˆ í•œ ë‹¨ì–´ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”."
        )},
            {"role": "user", "content": f"ì§ˆë¬¸: {question}\ní•µì‹¬ í‚¤ì›Œë“œ í•œ ë‹¨ì–´ë§Œ ì¶œë ¥í•´ì¤˜"}
    ]
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.2,
        max_tokens=10,
    )
    return response.choices[0].message.content.strip()

# ì•½ ê²€ìƒ‰ í•¨ìˆ˜ (íš¨ëŠ¥íš¨ê³¼ ë˜ëŠ” ì œí’ˆëª… í¬í•¨ ì—¬ë¶€ í™•ì¸)
def find_related_drugs(excel_df, user_query, top_n=5):
    excel_df.columns = excel_df.columns.str.strip()
    query = user_query.strip().lower()

    effect_mask = excel_df['íš¨ëŠ¥íš¨ê³¼'].astype(str).str.lower().str.contains(query, na=False)
    name_mask = excel_df['ì œí’ˆëª…'].astype(str).str.lower().str.contains(query, na=False)
    mask = effect_mask | name_mask

    matched = excel_df[mask]

    if matched.empty:
        return pd.DataFrame()

    def has_valid_image(row):
        img = row.get('ì €ì¥_ì´ë¯¸ì§€_íŒŒì¼ëª…', '')
        return isinstance(img, str) and img.strip() and os.path.isfile(os.path.join("images", img))

    matched = matched[matched.apply(has_valid_image, axis=1)]

    if matched.empty:
        return pd.DataFrame()

    if 'ì‚¬ìš©ì‹œì£¼ì˜ì‚¬í•­' not in matched.columns:
        matched['ì‚¬ìš©ì‹œì£¼ì˜ì‚¬í•­'] = ""

    columns_needed = ['ì œí’ˆëª…', 'íš¨ëŠ¥íš¨ê³¼', 'êµ¬ë¶„', 'ì €ì¥_ì´ë¯¸ì§€_íŒŒì¼ëª…', 'ì‚¬ìš©ì‹œì£¼ì˜ì‚¬í•­']
    return matched[columns_needed].drop_duplicates().head(top_n)

def ocr_page():
    st.title("ì•½ ì´ë¯¸ì§€ ì¸ì‹ ê¸°ë°˜ ì •ë³´ ì œê³µ ì‹œìŠ¤í…œ")

    marge_all = pd.read_excel("final_data.xlsx")
    for col in ['ì œí’ˆëª…', 'ì—…ì²´ëª…', 'ì‹ë³„í‘œê¸°']:
        marge_all[col] = marge_all[col].astype(str)
        marge_all[f'{col}_clean'] = marge_all[col].apply(clean_str)

    uploaded_files = st.file_uploader("ê¶ê¸ˆí•˜ì‹  ì•½ ì´ë¯¸ì§€ë“¤ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”", type=["jpg", "jpeg", "png"], accept_multiple_files=True)

    if uploaded_files:
        st.header("ì—…ë¡œë“œí•œ ì•½ ì‹ë³„í‘œê¸° í™•ì¸")
        edited_texts = []

        for i, uploaded_file in enumerate(uploaded_files):
            image = Image.open(uploaded_file).convert("RGB")
            cropped = crop_pill_area(image)
            st.image(cropped, caption=f"ì´ë¯¸ì§€ {i+1} í¬ë¡­ ì•½ ì´ë¯¸ì§€", width=200)

            ocr_text = easyocr_extract_text(cropped).upper()
            edited = st.text_input(f"ì•½ {i+1} ì‹ë³„í‘œê¸° (ì´ë¯¸ì§€ ì¸ì‹ì´ ì˜ëª» ë˜ì—ˆë‹¤ë©´ ìˆ˜ì •í•´ì£¼ì„¸ìš”)", value=ocr_text, key=f"ocr_edit_{i}")
            edited_texts.append(edited)

        combined_identifiers = list(set([clean_str(text) for text in edited_texts if text.strip()]))

        st.header("ì‹ë³„í‘œê¸° í™•ì¸ í›„ ì•½ì„ ì„ íƒí•˜ê³  ê°œìˆ˜ë¥¼ ì§€ì •í•˜ì„¸ìš”")

        candidates = pd.DataFrame()
        for ident in combined_identifiers:
            temp = marge_all[marge_all['ì‹ë³„í‘œê¸°_clean'] == ident]
            if temp.empty:
                temp = marge_all[marge_all['ì‹ë³„í‘œê¸°_clean'].apply(
                    lambda x: any(difflib.get_close_matches(ident, [x], cutoff=0.6))
                )]
            candidates = pd.concat([candidates, temp])

        candidates = candidates.drop_duplicates().reset_index(drop=True)

        if candidates.empty:
            st.warning("ì¡°ê±´ì— ë§ëŠ” ì•½ í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        if 'basket' not in st.session_state:
            st.session_state['basket'] = {}

        displayed_candidates = {}

        for display_idx, (_, row) in enumerate(candidates.iterrows()):
            key_cb = f"select_{display_idx}"
            key_qty = f"qty_{display_idx}"

            selected = st.checkbox(
                f"{row['ì‹ë³„í‘œê¸°']} - {row['ì œí’ˆëª…']} ({row['ì—…ì²´ëª…']})", 
                key=key_cb, 
                value=key_cb in st.session_state['basket']
            )

            displayed_candidates[key_cb] = row

            if selected:
                qty = st.number_input(f"â–¶ {row['ì œí’ˆëª…']} ìˆ˜ëŸ‰ ì„ íƒ", min_value=1, max_value=10, value=1, key=key_qty)
                st.session_state['basket'][key_cb] = {"quantity": qty}
            else:
                st.session_state['basket'].pop(key_cb, None)

            with st.expander(" â–¼ ì¶”ê°€ ì •ë³´ ë³´ê¸°"):
                st.markdown(f"- **ì œí˜•**: {row.get('ì œí˜•', 'ì •ë³´ ì—†ìŒ')}")
                st.markdown(f"- **ëª¨ì–‘**: {row.get('ëª¨ì–‘', 'ì •ë³´ ì—†ìŒ')}")
                st.markdown(f"- **ìƒ‰ê¹”**: {row.get('ìƒ‰ê¹”', 'ì •ë³´ ì—†ìŒ')}")
                st.markdown(f"- **ì„±ìƒ**: {row.get('ì„±ìƒ', 'ì •ë³´ ì—†ìŒ')}")
                img_url = row.get("ì œí’ˆì´ë¯¸ì§€")
                if isinstance(img_url, str) and img_url.startswith("http"):
                    st.image(img_url, width=150)
            st.markdown("---")

        basket_items = [displayed_candidates[key] for key in st.session_state['basket'].keys()]
        quantities = [st.session_state['basket'][key]['quantity'] for key in st.session_state['basket'].keys()]

        if basket_items:
            st.header("ì„ íƒí•œ ì•½ê³¼ ìˆ˜ëŸ‰ì„ í™•ì¸í•˜ê³  ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•˜ì„¸ìš”")
            question = st.text_input("ex) ë³´ê´€ë°©ë²•ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?, ì´ ì•½ë“¤ì„ ê°™ì´ ë¨¹ì–´ë„ ê´œì°®ë‚˜ìš”?")

            if question:
                if is_combination_question(question):
                    # ë³‘ìš© ì§ˆë¬¸ì¼ ë•Œ
                    st.markdown(check_drug_interaction_summary(basket_items))
                    st.markdown(check_ingredient_overlap_and_dosage(basket_items, quantities))
                else:
                    # ê°œë³„ ì•½ ì§ˆë¬¸ì¼ ë•Œ
                    for i, pill_info in enumerate(basket_items):
                        st.subheader(f"ì•½ {i+1}: {pill_info['ì œí’ˆëª…']}")
                        answer = chat_with_pill_info(pill_info, question)
                        st.write(answer)

                    st.markdown(check_drug_interaction_summary(basket_items))
                    st.markdown(check_ingredient_overlap_and_dosage(basket_items, quantities))

        else:
            st.info("ì„ íƒí•œ ì•½ì´ ì—†ìŠµë‹ˆë‹¤.")

# ë©”ì¸ í•¨ìˆ˜
def chatbot_page():
    st.title("AI ê¸°ë°˜ ë‹¤ì œì•½ë¬¼(ì¤‘ë³µ ë³µìš©) ì˜ˆë°© ì±—ë´‡")
    st.markdown("**ì•½ë¬¼ ê´€ë ¨ ê¶ê¸ˆí•œ ì ì´ë‚˜ ì¦ìƒì„ ì…ë ¥í•˜ë©´ ì¶”ì²œ ì•½ì„ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤.**")

    # ì‚¬ìš©ì ìƒíƒœ ì´ˆê¸°í™”
    if 'forbid' not in st.session_state:
        st.session_state.forbid = 'í•´ë‹¹ ì‚¬í•­ ì—†ìŒ'
    
    # ì„ íƒëœ ì•½í’ˆ ëª©ë¡ ì´ˆê¸°í™”
    if 'selected_drugs' not in st.session_state:
        st.session_state.selected_drugs = []
        
    # ìš”ì²­ ìƒíƒœ ì´ˆê¸°í™” (NEW: ìš”ì²­ ë²„íŠ¼ ìƒíƒœ ê´€ë¦¬)
    if 'request_submitted' not in st.session_state:
        st.session_state.request_submitted = False

    st.subheader("âš ï¸ ì‚¬ìš©ì ìƒíƒœ ì„ íƒ")
    forbid_options = ['ì„ì‚°ë¶€', 'ë…¸ì¸', 'ì¤‘ë³µì˜ì•½í’ˆ ë¬¸ì˜', 'í•´ë‹¹ ì‚¬í•­ ì—†ìŒ']    # ë²„íŠ¼ ì‘ì—… ì™„ë£Œ
    cols = st.columns(len(forbid_options))
    for i, option in enumerate(forbid_options):
        if cols[i].button(option, key=f"btn_{i}"):
            st.session_state.forbid = option
            # ìƒíƒœê°€ ë³€ê²½ë˜ë©´ ì„ íƒëœ ì•½í’ˆ ëª©ë¡ ì´ˆê¸°í™”
            st.session_state.selected_drugs = []
            # ìš”ì²­ ìƒíƒœ ì´ˆê¸°í™” (NEW)
            st.session_state.request_submitted = False
            st.success(f"ì„ íƒëœ ì‚¬ìš©ì ìƒíƒœ: {option}")
    
    # ë°ì´í„°
    marge_all = pd.read_excel("final_data.xlsx")
    main_df, preg_df, old_df, dup_df =  marge_all

    # [UPDATED] ì¤‘ë³µì˜ì•½í’ˆ ë¬¸ì˜ ì „ìš© ì…ë ¥ êµ¬ì„± - ë°˜ì‘í˜• ê°œì„  ë° ì¤‘ë³µ ID í•´ê²°
    placeholder = st.empty()
    
    # ì¤‘ë³µì˜ì•½í’ˆ ë¬¸ì˜ ì „ìš© ì…ë ¥ ë° ì²˜ë¦¬
    if st.session_state.forbid == 'ì¤‘ë³µì˜ì•½í’ˆ ë¬¸ì˜':
        # ì¤‘ë³µì˜ì•½í’ˆ ë¬¸ì˜ ì „ìš© ì…ë ¥ í•„ë“œ
        dup_question = st.text_input("ğŸ“ ì§ˆë¬¸ ë˜ëŠ” ì¦ìƒì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì¤‘ë³µë³µìš© ë“±)", key="dup_question_input")
        
        with placeholder.container():
            st.markdown("### ğŸ’Š í˜„ì¬ ë“œì‹œê³  ê³„ì‹  ì˜ì•½í’ˆ ê´€ë ¨ ì •ë³´ ì…ë ¥")

            with st.expander("ì¤‘ë³µ ë³µìš© ì£¼ì˜ ì˜ì•½í’ˆ ì¹´í…Œê³ ë¦¬ í™•ì¸í•˜ê¸°", expanded=True):
                dup_categories = [
                    'ì„ íƒí•˜ì„¸ìš”', 'í˜ˆì••ê°•í•˜ì‘ìš©ì˜ì•½í’ˆ', 'ë‹¹ë‡¨ë³‘ìš©ì œ', 'ì§€ì§ˆì €í•˜ì œ', 'ì†Œí™”ì„±ê¶¤ì–‘ìš©ì œ',
                    'í•´ì—´ì§„í†µì†Œì—¼ì œ', 'ì •ì‹ ì‹ ê²½ìš©ì œ', 'í˜¸í¡ê¸°ê´€ìš©ì•½', 'ë§ˆì•½ë¥˜ ì•„í¸ìœ ì‚¬ì œ', 'ìµœë©´ì§„ì •ì œ'
                ]
                selected_category = st.selectbox("ğŸ“‚ ì¹´í…Œê³ ë¦¬ ì„ íƒ", dup_categories, key="dup_category_select")

                if selected_category != 'ì„ íƒí•˜ì„¸ìš”':
                    related_dup_drugs = dup_df[dup_df['íš¨ëŠ¥êµ°'] == selected_category]
                    
                    if not related_dup_drugs.empty:
                        st.markdown(f"#### ğŸ“‹ '{selected_category}' ê´€ë ¨ ì˜ì•½í’ˆ ëª©ë¡:")
                        
                        # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ (í† í° ì œí•œ ë°©ì§€)
                        display_count = min(10, len(related_dup_drugs))
                        
                        # ì¤‘ë³µ í‚¤ ë¬¸ì œ í•´ê²°: ì¸ë±ìŠ¤ë¥¼ ì¶”ê°€í•˜ì—¬ ê³ ìœ í•œ í‚¤ ìƒì„±
                        for i in range(display_count):
                            row = related_dup_drugs.iloc[i]
                            product_name = row['ì œí’ˆëª…']
                            
                            # ê³ ìœ í•œ í‚¤ ìƒì„± ë°©ë²• - ì¸ë±ìŠ¤ ê°’ì„ í•¨ê»˜ ì‚¬ìš©
                            unique_key = f"drug_{i}_{product_name}"
                            
                            # ì²´í¬ë°•ìŠ¤ë¡œ ì•½í’ˆ ì„ íƒ ê¸°ëŠ¥ êµ¬í˜„ (ê³ ìœ í•œ í‚¤ ì‚¬ìš©)
                            if st.checkbox(f"{product_name}", key=unique_key):
                                # ì„ íƒëœ ì•½í’ˆ ëª©ë¡ì— ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€)
                                if product_name not in st.session_state.selected_drugs:
                                    st.session_state.selected_drugs.append(product_name)
                            elif product_name in st.session_state.selected_drugs:
                                # ì²´í¬ í•´ì œ ì‹œ ëª©ë¡ì—ì„œ ì œê±°
                                st.session_state.selected_drugs.remove(product_name)
                                
                        # ë” ë§ì€ ì•½í’ˆì´ ìˆìœ¼ë©´ ì•Œë¦¼
                        if len(related_dup_drugs) > 10:
                            st.info(f"í‘œì‹œëœ ì•½í’ˆ ì™¸ì— {len(related_dup_drugs) - 10}ê°œ ë” ìˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì‚¬ìš©í•´ë³´ì„¸ìš”.")
                    else:
                        st.info("ì„ íƒí•œ ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ” ì˜ì•½í’ˆ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # ì„ íƒëœ ì•½í’ˆ ëª©ë¡ í‘œì‹œ
            if st.session_state.selected_drugs:
                st.markdown("### ğŸ” ì„ íƒëœ ì•½í’ˆ ëª©ë¡")
                for selected_drug in st.session_state.selected_drugs:
                    st.markdown(f"- {selected_drug}")
        

        # GPT ì‘ë‹µ & ì•½ë¬¼ ì •ë³´ ì œê³µê³µ (ì¤‘ë³µì˜ì•½í’ˆ ë¬¸ì˜) - ìš”ì²­ ë²„íŠ¼ ì¶”ê°€ (NEW)
        if dup_question and st.session_state.selected_drugs:
            # ìš”ì²­ ë²„íŠ¼ ì¶”ê°€ (NEW)
            request_button = st.button("ğŸ“¤ ìš”ì²­í•˜ê¸°", key="submit_dup_request")
            
            # ìš”ì²­ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ìš”ì²­ ìƒíƒœë¥¼ Trueë¡œ ì„¤ì • (NEW)
            if request_button:
                st.session_state.request_submitted = True
                st.success("ìš”ì²­ì´ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤.")

                # --- í˜„ì¬ ì‘ì—…ì¤‘ ------------------------------------------------------------------------------------------------------------------------------

                if dup_question and st.session_state.request_submitted:
                    with st.spinner("ê´€ë ¨ ì•½í’ˆì„ ì°¾ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                        drug_df = find_related_drugs(main_df, selected_drug)

                    if drug_df.empty:
                        st.error("âŒ í•´ë‹¹ í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ì•½í’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        
                    else:
                        # ê²°ê³¼ ê°œìˆ˜ ì œí•œ (ìµœëŒ€ 5ê°œ)
                        display_count = min(5, len(drug_df))
                        limited_drug_df = drug_df.head(display_count)
                        
                        drug_summary_text = "ğŸ” ê´€ë ¨ ì•½í’ˆ ëª©ë¡:\n"
                        for _, row in limited_drug_df.iterrows():
                            name = row['ì œí’ˆëª…']
                            image_filename = row['ì €ì¥_ì´ë¯¸ì§€_íŒŒì¼ëª…']
                            image_path = os.path.join("images", image_filename)

                            if os.path.exists(image_path):
                                st.image(image_path, caption=name, width=300)
                            else:
                                st.warning(f"ì´ë¯¸ì§€ ì—†ìŒ: {image_filename}")

                            st.markdown(f"**ğŸ’Š {name}** ({row['êµ¬ë¶„']})")
                            st.markdown(f"**íš¨ëŠ¥:** {row['íš¨ëŠ¥íš¨ê³¼']}")

                            precautions = row.get("ì£¼ì˜ì‚¬í•­_ë³‘í•©", "")
                            if pd.notna(precautions) and str(precautions).strip() != "":
                                with st.expander("ğŸ“Œ ì‚¬ìš© ì‹œ ì£¼ì˜ì‚¬í•­ ë³´ê¸°"):
                                    st.markdown(str(precautions))
                            else:
                                st.markdown("â„¹ï¸ ì‚¬ìš© ì‹œ ì£¼ì˜ì‚¬í•­ ì •ë³´ ì—†ìŒ")


                # --- í˜„ì¬ ì‘ì—…ì¤‘ -------------------------------------------------------------------------------------------------------------------------------
            
            # ìš”ì²­ ë²„íŠ¼ì´ ëˆŒë ¤ì§„ ìƒíƒœì¼ ë•Œë§Œ API í˜¸ì¶œ ì‹¤í–‰ (NEW)
            if st.session_state.request_submitted:
                # ì„ íƒëœ ì•½í’ˆë§Œ í¬í•¨í•˜ì—¬ ìš”ì•½ ìƒì„± (í† í° ì œí•œ ë¬¸ì œ í•´ê²°)
                drug_dup_summary_text = "ğŸ” ê´€ë ¨ ì•½í’ˆ ëª©ë¡:\n"
                for drug in st.session_state.selected_drugs:
                    drug_dup_summary_text += f"- {drug}\n"
                
                messages = [
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì•½ë¬¼ ë³µìš© ì •ë³´ì™€ ë³‘ìš© ê¸ˆê¸° ë“±ì— ëŒ€í•´ ë‹µë³€í•˜ëŠ” ì•½ì‚¬ AIì…ë‹ˆë‹¤."},
                    {"role": "user", "content": f"ì•„ë˜ ì•½ ì •ë³´ ì°¸ê³ í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”:\n{drug_dup_summary_text}\n\nì§ˆë¬¸: {dup_question}"}
                ]
                
                # ë””ë²„ê¹…ìš© ë©”ì‹œì§€ ì¶œë ¥ (ì„ íƒì‚¬í•­)
                print(messages)
                
                try:
                    response = client.chat.completions.create(
                        model=os.environ['OPENAI_API_MODEL'],
                        messages=messages,
                        temperature=0.5,
                        max_tokens=500,
                    )
                    answer = response.choices[0].message.content
                    st.markdown("### ğŸ’¡ GPT ë‹µë³€:")
                    st.markdown(answer)
                    
                except Exception as e:
                    st.error(f"GPT ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    st.info("ğŸ’¡ íŒ: ì„ íƒí•œ ì•½í’ˆì´ ë„ˆë¬´ ë§ìœ¼ë©´ í† í° ì œí•œì— ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•„ìš”í•œ ì•½í’ˆë§Œ ì„ íƒí•´ì£¼ì„¸ìš”.")
        elif dup_question and not st.session_state.selected_drugs:
            st.warning("âš ï¸ ì§ˆë¬¸í•˜ê¸° ì „ì— ì•½í’ˆì„ í•˜ë‚˜ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.")
    else:
        # ì¼ë°˜ ì§ˆë¬¸ ì…ë ¥ í•„ë“œ (ì¤‘ë³µì˜ì•½í’ˆ ë¬¸ì˜ê°€ ì•„ë‹ ë•Œë§Œ í‘œì‹œ)
        user_question = st.text_input("ğŸ“ ì§ˆë¬¸ ë˜ëŠ” ì¦ìƒì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ê°ê¸°, ë¹„íƒ€ë¯¼ ë“±)", key="general_question_input")
        
        # ìš”ì²­ ë²„íŠ¼ ì¶”ê°€ (NEW)
        if user_question:
            request_button = st.button("ğŸ“¤ ìš”ì²­í•˜ê¸°", key="submit_general_request")
            
            # ìš”ì²­ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ìš”ì²­ ìƒíƒœë¥¼ Trueë¡œ ì„¤ì • (NEW)
            if request_button:
                st.session_state.request_submitted = True
                st.success("ìš”ì²­ì´ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì¼ë°˜ ì§ˆë¬¸ì— ëŒ€í•œ ì²˜ë¦¬ - ìš”ì²­ ë²„íŠ¼ì´ ëˆŒë ¤ì§„ ìƒíƒœì¼ ë•Œë§Œ ì‹¤í–‰ (NEW)
        if user_question and st.session_state.request_submitted:
            with st.spinner("ê´€ë ¨ ì•½í’ˆì„ ì°¾ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                drug_df = find_related_drugs(main_df, user_question)

            if drug_df.empty:
                st.error("âŒ í•´ë‹¹ í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ì•½í’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
            else:
                # ê²°ê³¼ ê°œìˆ˜ ì œí•œ (ìµœëŒ€ 5ê°œ)
                display_count = min(5, len(drug_df))
                limited_drug_df = drug_df.head(display_count)
                
                drug_summary_text = "ğŸ” ê´€ë ¨ ì•½í’ˆ ëª©ë¡:\n"
                for _, row in limited_drug_df.iterrows():
                    name = row['ì œí’ˆëª…']
                    image_filename = row['ì €ì¥_ì´ë¯¸ì§€_íŒŒì¼ëª…']
                    image_path = os.path.join("images", image_filename)

                    if os.path.exists(image_path):
                        st.image(image_path, caption=name, width=300)
                    else:
                        st.warning(f"ì´ë¯¸ì§€ ì—†ìŒ: {image_filename}")

                    st.markdown(f"**ğŸ’Š {name}** ({row['êµ¬ë¶„']})")
                    st.markdown(f"**íš¨ëŠ¥:** {row['íš¨ëŠ¥íš¨ê³¼']}")

                    precautions = row.get("ì£¼ì˜ì‚¬í•­_ë³‘í•©", "")
                    if pd.notna(precautions) and str(precautions).strip() != "":
                        with st.expander("ğŸ“Œ ì‚¬ìš© ì‹œ ì£¼ì˜ì‚¬í•­ ë³´ê¸°"):
                            st.markdown(str(precautions))
                    else:
                        st.markdown("â„¹ï¸ ì‚¬ìš© ì‹œ ì£¼ì˜ì‚¬í•­ ì •ë³´ ì—†ìŒ")

                    # ì‚¬ìš©ì ìƒíƒœì— ë”°ë¼ ì¶”ê°€ ì •ë³´ ì¶œë ¥
                    if st.session_state.forbid == 'ì„ì‚°ë¶€':
                        preg_info = preg_df[preg_df['ì œí’ˆëª…'] == name]
                        if not preg_info.empty:
                            st.error("ğŸš¨ ì„ì‚°ë¶€ ê¸ˆê¸° ì•½ë¬¼ì…ë‹ˆë‹¤!")
                            st.markdown(f"**ê¸ˆê¸°ë“±ê¸‰:** {preg_info.iloc[0]['ê¸ˆê¸°ë“±ê¸‰']}")
                            st.markdown(f"**ìƒì„¸ì •ë³´:** {preg_info.iloc[0]['ìƒì„¸ì •ë³´']}")

                    elif st.session_state.forbid == 'ë…¸ì¸':
                        old_info = old_df[old_df['ì œí’ˆëª…'] == name]
                        if not old_info.empty:
                            st.warning("âš ï¸ ë…¸ì¸ ì£¼ì˜ ì•½ë¬¼ì…ë‹ˆë‹¤.")
                            st.markdown(f"**ì•½í’ˆìƒì„¸ì •ë³´:** {old_info.iloc[0]['ì•½í’ˆìƒì„¸ì •ë³´']}")

                    st.markdown("---")
                    drug_summary_text += f"- {name}\n"
                
                # ë” ë§ì€ ê²°ê³¼ê°€ ìˆìŒì„ ì•Œë¦¼
                if len(drug_df) > display_count:
                    st.info(f"âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ë§ì•„ ìƒìœ„ {display_count}ê°œë§Œ í‘œì‹œí•©ë‹ˆë‹¤. (ì´ {len(drug_df)}ê°œ ê²€ìƒ‰ë¨)")

                # GPT ì‘ë‹µ (ì¼ë°˜ ì§ˆë¬¸)
                messages = [
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì•½ë¬¼ ë³µìš© ì •ë³´ì™€ ë³‘ìš© ê¸ˆê¸° ë“±ì— ëŒ€í•´ ë‹µë³€í•˜ëŠ” ì•½ì‚¬ AIì…ë‹ˆë‹¤."},
                    {"role": "user", "content": f"ì•„ë˜ ì•½ ì •ë³´ ì°¸ê³ í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”:\n{drug_summary_text}\n\nì§ˆë¬¸: {user_question}"}
                ]
                
                # ë””ë²„ê¹…ìš© ë©”ì‹œì§€ ì¶œë ¥ (ì„ íƒì‚¬í•­)
                print(messages)

                try:
                    response = client.chat.completions.create(
                        model=os.environ['OPENAI_API_MODEL'],
                        messages=messages,
                        temperature=0.5,
                        max_tokens=500,
                    )
                    answer = response.choices[0].message.content
                    st.markdown("### ğŸ’¡ GPT ë‹µë³€:")
                    st.markdown(answer)
                except Exception as e:
                    st.error(f"GPT ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ì±—ë´‡ í˜ì´ì§€ êµ¬í˜„
def chatbot2_page():
    st.title("ğŸ’Š AI ê¸°ë°˜ ì•½í’ˆ ì¶”ì²œ ì±—ë´‡")
    st.markdown("ì‚¬ìš©ì ì§ˆë¬¸ì— ë”°ë¼ ì•½ ì •ë³´ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.")
    user_question = st.text_input("â“ ì¦ìƒì´ë‚˜ ê¶ê¸ˆí•œ ì•½ì„ ì…ë ¥í•˜ì„¸ìš”\n ì˜ˆì‹œ) ë‚´ê°€ ì§€ê¸ˆ ëª¸ì´ ì—´ì´ ë‚˜ê³  ì½§ë¬¼ì´ ë‚˜ì„œ ì½”ê°€ ë§‰í˜€ ì–´ë–¤ ì•½ì´ ì¢‹ì„ê¹Œ? ")
    df = load_excel_data()

    if user_question:
        if is_small_talk(user_question):
            st.markdown("ğŸ¤– **ê¸°ë³¸ ëŒ€í™” ì‘ë‹µì…ë‹ˆë‹¤.**")
            base_response = f"ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
            st.success("âœ… AI ì‘ë‹µ ì™„ë£Œ")
            st.markdown(base_response)

        else:
            st.markdown("ğŸ¤– **LlamaIndex ê¸°ë°˜ RAGë¡œ ë‹µë³€ ì¤‘...**")
            query_engine = get_query_engine()
            response = query_engine.query(user_question)
            st.success("âœ… AI ì‘ë‹µ ì™„ë£Œ")

            full_response = response.response

            # ì •ê·œì‹ìœ¼ë¡œ ì •ë³´ ì¶”ì¶œ
            product_match = re.search(r"ì œí’ˆëª…\s*[:ï¼š]\s*(.+)", full_response)
            class_match = re.search(r"êµ¬ë¶„\s*[:ï¼š]\s*(.+)", full_response)
            effect_match = re.search(r"íš¨ëŠ¥íš¨ê³¼\s*[:ï¼š]\s*(.+)", full_response)

            product_name = product_match.group(1).strip() if product_match else "ì•Œ ìˆ˜ ì—†ìŒ"
            product_class = class_match.group(1).strip() if class_match else ""
            effect_text = effect_match.group(1).strip() if effect_match else ""

            answer_text = full_response
            for pattern in [r"ì œí’ˆëª…\s*[:ï¼š].+", r"êµ¬ë¶„\s*[:ï¼š].+", r"íš¨ëŠ¥íš¨ê³¼\s*[:ï¼š].+"]:
                answer_text = re.sub(pattern, "", answer_text).strip()

            if product_name.lower() != "ì•Œ ìˆ˜ ì—†ìŒ":
                if product_name.lower() != "xxx":
                    st.markdown(f"### ğŸ’Š {product_name} ({product_class})")
                    st.markdown(f"**AI ë‹µë³€:** {answer_text}")

                    # ğŸ”¹ êµ¬ê¸€ ì´ë¯¸ì§€ ì¶œë ¥
                    google_img_url = google_image_search(google_key, google_cse, product_name, num=1)
                    if google_img_url:
                        st.image(google_img_url[0], caption=f"{product_name} (ê²€ìƒ‰ ì´ë¯¸ì§€)", width=300)
                    else:
                        st.info("ğŸ” êµ¬ê¸€ ì´ë¯¸ì§€ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")

                    # ğŸ”¹ ì¶”ê°€ ì„¤ëª… ì¶œë ¥
                    st.markdown("ì¶”ê°€ì ì¸ ì •ë³´ì…ë‹ˆë‹¤.")
                    st.markdown(f"ğŸ’Š {product_name} ({product_class})")
                    st.markdown(f"**íš¨ëŠ¥íš¨ê³¼:** {effect_text}")

                    # ğŸ”¹ ì£¼ì˜ì‚¬í•­ ì¶œë ¥ (ì—‘ì…€ì—ì„œ í•´ë‹¹ row ê²€ìƒ‰)
                    excel_row = df[df["ì œí’ˆëª…"] == product_name]
                    if not excel_row.empty:
                        warning = excel_row.iloc[0].get("ì‚¬ìš©ì‹œì£¼ì˜ì‚¬í•­", "")
                        if isinstance(warning, str) and warning.strip():
                            with st.expander("ğŸ“Œ ì‚¬ìš©ì‹œ ì£¼ì˜ì‚¬í•­ ë³´ê¸°"):
                                st.markdown(warning)
                        else:
                            st.info("âš ï¸ ì£¼ì˜ì‚¬í•­ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.warning("â— ì œí’ˆëª…ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")


def main():
    st.sidebar.title("ì„œë¹„ìŠ¤ ì„ íƒ")
    page = st.sidebar.radio("ë©”ë‰´", ["ì•Œì•½ ì´ë¯¸ì§€ ê²€ìƒ‰", "ì•½ ì •ë³´ ê²€ìƒ‰ ì±—ë´‡"])

    if page == "ì•Œì•½ ì´ë¯¸ì§€ ê²€ìƒ‰":
        ocr_page()
        chatbot_page()
    elif page == "ì•½ ì •ë³´ ê²€ìƒ‰ ì±—ë´‡":
        chatbot2_page()

# ì‹¤í–‰
if __name__ == "__main__":
    main()
 # type: ignore