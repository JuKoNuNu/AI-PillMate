import os
import re
import requests
from dotenv import load_dotenv
import streamlit as st
import pandas as pd
from PIL import Image
from openai import OpenAI as OpenAIClient
from llama_index.core import VectorStoreIndex, Document, StorageContext, load_index_from_storage, Settings
from llama_index.llms.openai import OpenAI as LlamaOpenAI
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core.response_synthesizers import get_response_synthesizer
from llama_index.core.retrievers import VectorIndexRetriever


load_dotenv()
openai_key = os.getenv("OPENAI_API_KEY")
google_key = os.getenv("GOOGLE_API_KEY")
google_cse = os.getenv("GOOGLE_CSE_ID")
naver_client_id = os.getenv("NAVER_API_ID")
naver_client_secret = os.getenv("NAVER_API_SECRET")

client = OpenAIClient(api_key=openai_key)
os.environ["OPENAI_API_KEY"] = openai_key


# ì—‘ì…€ ë°ì´í„° ë¡œë”©
@st.cache_data
def load_excel_data():
    return pd.read_excel("txta.xlsx")

df = load_excel_data()

# ë¬¸ì„œ ë¡œë”© (RAGìš©)
def load_docs_from_excel(filepath):
    df_local = pd.read_excel(filepath)
    documents = []
    for _, row in df_local.iterrows():
        content = f"""
        ì œí’ˆëª…: {row.get('ì œí’ˆëª…')}
        íš¨ëŠ¥íš¨ê³¼: {row.get('íš¨ëŠ¥íš¨ê³¼')}
        êµ¬ë¶„: {row.get('êµ¬ë¶„')}
        ì‚¬ìš©ì‹œì£¼ì˜ì‚¬í•­: {row.get('ì‚¬ìš©ì‹œì£¼ì˜ì‚¬í•­', '')}
        ì €ì¥_ì´ë¯¸ì§€_íŒŒì¼ëª…: {row.get('ì €ì¥_ì´ë¯¸ì§€_íŒŒì¼ëª…', '')}
        """
        documents.append(Document(text=content.strip()))
    return documents

# LlamaIndex ì¿¼ë¦¬ ì—”ì§„ ì„¤ì •

@st.cache_resource(show_spinner=True)
def get_query_engine():
    persist_dir = "./index_store"
    
    if not os.path.exists(persist_dir):
        docs = load_docs_from_excel("txta.xlsx")
        index = VectorStoreIndex.from_documents(docs)
        index.storage_context.persist(persist_dir=persist_dir)

    storage_context = StorageContext.from_defaults(persist_dir=persist_dir)
    index = load_index_from_storage(storage_context)

    # LLM ì„¤ì •
    llm = LlamaOpenAI(
        model="gpt-4o-mini",
        temperature=0.3,
        system_prompt=(
            "ë‹¹ì‹ ì€ í•œêµ­ì–´ë¡œë§Œ ëŒ€ë‹µí•˜ëŠ” ì•½ì‚¬ì…ë‹ˆë‹¤. í•­ìƒ ì¹œì ˆí•˜ê³  ìƒì„¸í•˜ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.\n"
            "ë¨¼ì € ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\n"
            "ë‹¹ì‹ ì€ ì•½ì‚¬ë¡œì„œ ì•½ì— ëŒ€í•œ ì •ë³´ë¥¼ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë§ê²Œ ì¹œì ˆí•˜ê³  ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤."
            "ì˜ˆì‹œ"
            "ê°ê¸°ì— ê±¸ë¦°ê±° ê°™ì•„ -> ë‹¹ì‹ ì€ ê°ê¸°ì— ê±¸ë ¸ìŠµë‹ˆë‹¤. ê°ê¸°ì˜ ì¦ìƒì€ ì—´, ê¸°ì¹¨, ì½§ë¬¼ ë“±ì´ ìˆìœ¼ë©° ì´ ì•½ 'ì œí’ˆëª…'ì€ ì´ëŸ¬í•œ ì¦ìƒì— íš¨ê³¼ì ì…ë‹ˆë‹¤. ì‚¬ìš©ë°©ë²•ì€ XXX, ë¶€ì‘ìš©ì´ë‚˜ ì£¼ì˜ì‚¬í•­ì€ XXXì…ë‹ˆë‹¤."
            "í•˜ê³  ì§„ì§œ ì•½ì‚¬ê°€ ì¶©ê³ í•˜ë“¯ì´ ìœ ì‚¬í•œ ì•½ë„ ì¶”ì²œí•´ì¤„ ìˆ˜ ìˆìœ¼ë©´ ì¶”ì²œí•´ì¤˜"
            "ì œí’ˆëª… : XXX\n"
            "êµ¬ë¶„ : XXX\n"
            "íš¨ëŠ¥íš¨ê³¼ : XXX\n\n"
            "ê·¸ ë‹¤ìŒ ì¤„ì— ë‹¤ìŒ ì§€ì¹¨ì„ ë”°ë¦…ë‹ˆë‹¤:\n"
            "\n"
        )
    )
    Settings.llm = llm

    # êµ¬ì„±
    retriever = VectorIndexRetriever(index=index, similarity_top_k=5)
    response_synthesizer = get_response_synthesizer(response_mode="tree_summarize")

    query_engine = RetrieverQueryEngine(
        retriever=retriever,
        response_synthesizer=response_synthesizer
    )

    return query_engine

# êµ¬ê¸€ ì´ë¯¸ì§€ ê²€ìƒ‰ (ì´ë¯¸ì§€ URL ë¦¬ìŠ¤íŠ¸ ë°˜í™˜)
def google_image_search(api_key, cse_id, query, num=1):
    url = "https://www.googleapis.com/customsearch/v1"
    params = {
        "key": api_key,
        "cx": cse_id,
        "q": query,
        "searchType": "image",
        "num": num,
    }
    response = requests.get(url, params=params)
    results = response.json()
    return [item["link"] for item in results.get("items", [])]

# Streamlitì— ì´ë¯¸ì§€ í‘œì‹œ í•¨ìˆ˜
def show_images(image_urls):
    for url in image_urls:
        st.image(url, width=300)

# GPTë¡œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
def extract_keyword(question):
    messages = [
            {"role": "system", "content": (
            "ë‹¹ì‹ ì€ í•œêµ­ì–´ ì§ˆë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì •í™•íˆ í•œ ë‹¨ì–´ë¡œ ì¶”ì¶œí•˜ëŠ” AI ì•½ì‚¬ì…ë‹ˆë‹¤. "
            "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ì¦ìƒ ë˜ëŠ” ì•½ê³¼ ê´€ë ¨ëœ ë‹¨ì–´ë§Œ ë½‘ì•„ì•¼ í•©ë‹ˆë‹¤. "
            "ì˜ˆì‹œ:\n"
            "'ê°ê¸° ê±¸ë¦° ê²ƒ ê°™ì•„' â†’ 'ê°ê¸°'\n"
            "'ë‘í†µì´ ì‹¬í•´ìš”' â†’ 'ë‘í†µ'\n"
            "'ì–´ì§€ëŸ½ê³  ê¸°ìš´ì´ ì—†ì–´ìš”' â†’ 'ì–´ì§€ëŸ¼ì¦'\n"
            "'ëª©ì´ ë”°ë”ê±°ë¦¬ê³  ì—´ì´ ë‚˜ìš”' â†’ 'ëª©ê°ê¸°'\n"
            "ì •í™•íˆ í•œ ë‹¨ì–´ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”."
        )},
            {"role": "user", "content": f"ì§ˆë¬¸: {question}\ní•µì‹¬ í‚¤ì›Œë“œ í•œ ë‹¨ì–´ë§Œ ì¶œë ¥í•´ì¤˜"}
    ]
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.2,
        max_tokens=10,
    )
    return response.choices[0].message.content.strip()

# ì•½ ê²€ìƒ‰ í•¨ìˆ˜ (íš¨ëŠ¥íš¨ê³¼ ë˜ëŠ” ì œí’ˆëª… í¬í•¨ ì—¬ë¶€ í™•ì¸)
def find_related_drugs(excel_df, user_query, top_n=5):
    excel_df.columns = excel_df.columns.str.strip()
    query = user_query.strip().lower()

    effect_mask = excel_df['íš¨ëŠ¥íš¨ê³¼'].astype(str).str.lower().str.contains(query, na=False)
    name_mask = excel_df['ì œí’ˆëª…'].astype(str).str.lower().str.contains(query, na=False)
    mask = effect_mask | name_mask

    matched = excel_df[mask]

    if matched.empty:
        return pd.DataFrame()

    def has_valid_image(row):
        img = row.get('ì €ì¥_ì´ë¯¸ì§€_íŒŒì¼ëª…', '')
        return isinstance(img, str) and img.strip() and os.path.isfile(os.path.join("images", img))

    matched = matched[matched.apply(has_valid_image, axis=1)]

    if matched.empty:
        return pd.DataFrame()

    if 'ì‚¬ìš©ì‹œì£¼ì˜ì‚¬í•­' not in matched.columns:
        matched['ì‚¬ìš©ì‹œì£¼ì˜ì‚¬í•­'] = ""

    columns_needed = ['ì œí’ˆëª…', 'íš¨ëŠ¥íš¨ê³¼', 'êµ¬ë¶„', 'ì €ì¥_ì´ë¯¸ì§€_íŒŒì¼ëª…', 'ì‚¬ìš©ì‹œì£¼ì˜ì‚¬í•­']
    return matched[columns_needed].drop_duplicates().head(top_n)

# ì±—ë´‡ í˜ì´ì§€ êµ¬í˜„
def chatbot_page():
    st.title("ğŸ’Š AI ê¸°ë°˜ ì•½í’ˆ ì¶”ì²œ ì±—ë´‡")
    st.markdown("ì‚¬ìš©ì ì§ˆë¬¸ì— ë”°ë¼ ì•½ ì •ë³´ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.")

    mode = st.radio("ë°©ì‹ ì„ íƒ", ["ê¸°ì¡´ ë°©ì‹ (í‚¤ì›Œë“œ ê¸°ë°˜)", "RAG ê¸°ë°˜ (LlamaIndex)"])
    user_question = st.text_input("â“ ì¦ìƒì´ë‚˜ ê¶ê¸ˆí•œ ì•½ì„ ì…ë ¥í•˜ì„¸ìš”")

    if user_question:
        if mode == "ê¸°ì¡´ ë°©ì‹ (í‚¤ì›Œë“œ ê¸°ë°˜)":
            st.markdown("ğŸ” **GPT í‚¤ì›Œë“œ ê¸°ë°˜ ì•½ ê²€ìƒ‰ ì¤‘...**")
            keyword = extract_keyword(user_question)
            st.write("ğŸ”‘ ì¶”ì¶œëœ í‚¤ì›Œë“œ:", keyword)
            results = find_related_drugs(df, keyword)


            if not results.empty:
                for _, row in results.iterrows():

                    name = row['ì œí’ˆëª…']
                    excel_img = row['ì €ì¥_ì´ë¯¸ì§€_íŒŒì¼ëª…']
                    local_img_path = os.path.join("images", excel_img)

                    st.markdown(f"### ğŸ’Š {row['ì œí’ˆëª…']} ({row['êµ¬ë¶„']})")
                    local_img_path = os.path.join("images", row['ì €ì¥_ì´ë¯¸ì§€_íŒŒì¼ëª…'])
                    if os.path.isfile(local_img_path):
                        st.image(local_img_path, width=300)
                    google_img_url = google_image_search(google_key, google_cse, name, num=1)
                    if google_img_url:
                        st.image(google_img_url[0], caption=f"{name} (ê²€ìƒ‰ ì´ë¯¸ì§€)", use_container_width=300)
                    else:
                        st.info("ğŸ” êµ¬ê¸€ ì´ë¯¸ì§€ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                    st.markdown(f"### ğŸ’Š {name} ({row['êµ¬ë¶„']})")
                    st.markdown(f"**íš¨ëŠ¥íš¨ê³¼:** {row['íš¨ëŠ¥íš¨ê³¼']}")
                    if row['ì‚¬ìš©ì‹œì£¼ì˜ì‚¬í•­']:
                        with st.expander("ğŸ“Œ ì‚¬ìš©ì‹œ ì£¼ì˜ì‚¬í•­ ë³´ê¸°"):
                            st.markdown(row['ì‚¬ìš©ì‹œì£¼ì˜ì‚¬í•­'])
                    else:
                        st.info("âš ï¸ ì£¼ì˜ì‚¬í•­ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

                    st.markdown("---")
            else:
                st.warning(f"âŒ '{keyword}' ë˜ëŠ” '{user_question}' ê´€ë ¨ ì•½í’ˆì„ ì°¾ì§€ ëª»í–ˆì–´ìš”.")

        else:
            st.markdown("ğŸ¤– **LlamaIndex ê¸°ë°˜ RAGë¡œ ë‹µë³€ ì¤‘...**")
            query_engine = get_query_engine()
            response = query_engine.query(user_question)
            st.success("âœ… AI ì‘ë‹µ ì™„ë£Œ")

            full_response = response.response

            # ì •ê·œì‹ìœ¼ë¡œ ì •ë³´ ì¶”ì¶œ
            product_match = re.search(r"ì œí’ˆëª…\s*[:ï¼š]\s*(.+)", full_response)
            class_match = re.search(r"êµ¬ë¶„\s*[:ï¼š]\s*(.+)", full_response)
            effect_match = re.search(r"íš¨ëŠ¥íš¨ê³¼\s*[:ï¼š]\s*(.+)", full_response)

            product_name = product_match.group(1).strip() if product_match else "ì•Œ ìˆ˜ ì—†ìŒ"
            product_class = class_match.group(1).strip() if class_match else ""
            effect_text = effect_match.group(1).strip() if effect_match else ""

            answer_text = full_response
            for pattern in [r"ì œí’ˆëª…\s*[:ï¼š].+", r"êµ¬ë¶„\s*[:ï¼š].+", r"íš¨ëŠ¥íš¨ê³¼\s*[:ï¼š].+"]:
                answer_text = re.sub(pattern, "", answer_text).strip()

            if product_name.lower() != "ì•Œ ìˆ˜ ì—†ìŒ":
                st.markdown(f"### ğŸ’Š {product_name} ({product_class})")
                st.markdown(f"**AI ë‹µë³€:** {answer_text}")

                # ğŸ”¹ ë¡œì»¬ ì´ë¯¸ì§€ ì¶œë ¥
                excel_row = df[df["ì œí’ˆëª…"].str.lower() == product_name.lower()]
                if not excel_row.empty:
                    local_img = excel_row.iloc[0].get("ì €ì¥_ì´ë¯¸ì§€_íŒŒì¼ëª…", "")
                    local_img_path = os.path.join("images", local_img)
                    if os.path.isfile(local_img_path):
                        st.image(local_img_path, width=300)

                # ğŸ”¹ êµ¬ê¸€ ì´ë¯¸ì§€ ì¶œë ¥
                google_img_url = google_image_search(google_key, google_cse, product_name, num=1)
                if google_img_url:
                    st.image(google_img_url[0], caption=f"{product_name} (ê²€ìƒ‰ ì´ë¯¸ì§€)", width=300)
                else:
                    st.info("ğŸ” êµ¬ê¸€ ì´ë¯¸ì§€ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")

                # ğŸ”¹ íš¨ëŠ¥íš¨ê³¼ ì¶œë ¥
                st.markdown(f"**íš¨ëŠ¥íš¨ê³¼:** {effect_text}")

                # ğŸ”¹ ì£¼ì˜ì‚¬í•­ ì¶œë ¥
                if not excel_row.empty:
                    warning = excel_row.iloc[0].get("ì‚¬ìš©ì‹œì£¼ì˜ì‚¬í•­", "")
                    if isinstance(warning, str) and warning.strip():
                        with st.expander("ğŸ“Œ ì‚¬ìš©ì‹œ ì£¼ì˜ì‚¬í•­ ë³´ê¸°"):
                            st.markdown(warning)
                    else:
                        st.info("âš ï¸ ì£¼ì˜ì‚¬í•­ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                # ğŸ”¹ ì¶”ê°€ ì„¤ëª… ì¶œë ¥
                
                
            
            else:
                st.warning("â— ì œí’ˆëª…ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

def main():
    chatbot_page()

if __name__ == "__main__":
    main()
